---
profile_photo: /assets/img/Shreya_IEEE.png
---

![Your Name]({{ page.profile_photo }})
# Shreya Upadhyay

## Research Interest 
- Behavioural Speech Signal Processing, Machine Learning, Speech Emotion Recognition, Affective Computing, Sound Event Detection, Automatic Speech Recognition, Cross-Corpus Transfer Learning

## Education
- PhD, Electrical Engineering - National Tsing Hua University (NTHU), Taiwan (_2019/09_ - _Present_ )								       		
- MTech, Computer Engineering - K. J. Somaiya College of Engineering (_2016/06 - 2018/10_)	 			        		
- BE, Computer Engineering - Mumbai University (_2009/06 - 2013/07_)

## Research Experience
### Behavioral Information and Interaction Computation Lab (BIIC), NTHU (_2019/09 - Present_)
#### Speech Emotion Recognition
- Pretrained Layer-Constrained Cross-Lingual SER
- Utilizing Rater-Expanded Label Space for Consensus-based SER (TAFFC 24)
- Affective Priming on Emotional Annotations (ACII 23)
- Phonetic-Anchor based Cross-Lingual SER (ICASSP 23)
- Monolog v/s Conversation Speech Data Analysis (ACII 22)

#### Fairness
- Gender Fairness Generalizability in Cross-Corpus Scenario
- Balancing Speaker-Rater Fairness for Gender-Neutral SER (ICASSP 24)

#### Automatic Speech Recognition
- Implementing the Taiwanese Mandarin Forced Aligner
- Utilizing Large Speech Production SSL Models

#### Sound Event Detection
- Phoneme-Level Acoustic Learning for Rare Sound Event Detection (INTERSPEECH 20)
- Sound Event Localization and Detection

#### Affective Multimedia
- Integrating Annotator’s Subjectivity in Multimedia Emotion Recognition System
- Modelling Multimodal Systems with Verbal and Non-Verbal Human Sound Events (EUSIPCO 22)

#### Dataset Collection and Creation
- Taiwanese Mandarin Affective Podcast Dataset Collection (ACII 23)
- Synthetic Scene and Event Background Noise Dataset Creation for ASR

### K.J. Somaiya College of Engineering (KJSCE), India (_2016/06 - 2018/10_)
#### Affective and Behavioural Computing
- Attention-based Modelling for Accent Classification
- Dataset Collection Interface Creation for Judgement Questionnaire
- Early-Later Stage Confidence Behaviour Prediction of Online Platform Learners (ICCUBEA 18)


## Projects
### MSP-Lab, University of Texas at Dallas, USA (_2021/07 - Present_)
- Affective Mandarin Taiwanese Podcast Database Collection
- Phonetic-based Cross-Lingual Speech Emotion Recognition
- Effect of Affective Priming on Emotional Annotations
- Monolog v/s Conversational Speech on Recognizing Emotion

### C-Media Electronics Incorporation (C-Media Inc.), Taiwan (_2021/02 - 2021/07_)
- Implement AI De-Reverberation De-Noise Algorithm Using Deep Noise Suppression

## Internships
### Industrial Technology Research Institute (ITRI), Taiwan (_2022/06 - 2022/12_)

- Golf Swing Action Detection and Confidence Prediction
- Event Detection in Baseball Matches Using Audio-Only Features

### Research Innovation Incubation Design Labs (Riidl), India (_2018/07 - 2019/02_)
- Live Video Object Detection
- Speech Acoustic Analysis

## Teaching Assistance
#### Introduction to Digital Signal Processing, NTHU (_2022/02 - 2022/07_)
#### Introduction to Machine Learning, NTHU (_2021/09 - 2022/01_)
#### Machine Learning, KJSCE (_2017/02 - 2017/06_)
#### Design and Analysis of Algorithm, KJSCE (_2016/08 - 2017/01_)

## Awards & Honors

- NTHU International Student Scholarship, 2019 - 2024
- CTCI Foundation Research Scholarship, 2023
- ICASSP PROGRESS Award, 2023
- Google Travel Grant, 2023
- National Science and Technology Council (NSTC) Travel Grant, 2023
- Poster in Women in Machine Learning (WiML) Workshop, NeurIPS, 2022
- ACII Student Travel Grant, 2022
- Session Chair, 30th European Signal Processing Conference (EUSIPCO), 2022
- Merry Electroacoustic Paper Award (Finalists), 2020
- Poster in YFRS Workshop, Interspeech, 2018

## Skills

- Corpora Collection BIIC-Podcast (Affective Corpus)
- Speech Signal Processing Tools openSMILE, librosa, Praat, Fairseq
- Speech Production Models Wav2vec2.0, Hubert, WavLM, Whisper
- Computer Vision Tools OpenCV, OpenFace
- ASR Tools Kaldi, Forced Aligners (MFA)
- Programming Python, C++, MATLAB, HTML
- Machine Learning Libraries Pytorch, TensorFlow, Docker, scikit-learn
- Other Tools & Familiar OS LaTex, Git (Github and Gitlab), Linux, Windows

## Reviewer Experience

- International Conference on Affective Computing and Intelligent Interactions (ACII)
- ACM International Conference on Multimodal Interaction (ICMI)
- IEEE Transactions on Affective Computing
- Interspeech


## Publications
### Journal Paper
1. Upadhyay Shreya G., Woan-Shiuan Chien, Bo-Hao Su, and Chi-Chun Lee. ”Learning With Rater-Expanded
Label Space to Improve Speech Emotion Recognition.” IEEE Transactions on Affective Computing, 2024.
2. Upadhyay Shreya G., Luz Martinez-Lucas, William Katz, Carlos Busso, and Chi-Chun Lee. “Unsupervised
Cross-Corpus Speech Emotion Recognition using Phonetic Anchor-Governed Transfer Learning Infrastructure.”
IEEE Transactions on Affective Computing. (Under review)
3. Woan-Shiuan Chien, Upadhyay Shreya G., Wei-Cheng Lin, Carlos Busso, and Chi-Chun Lee. “Monologue
versus Conversation: Impact of Emotion Perception and Acoustic Variability on Speech Emotion Recognition.”
IEEE Transactions on Affective Computing. (Under review)
4. Luz Martinez-Lucas, Ali Salman, Seong-Gyun Leem, Upadhyay Shreya G., Chi-Chun Lee, and Carlos
Busso. “Affective Priming in Emotional Annotations and its Effect on Speech Emotion Recognition.” IEEE
Transactions on Affective Computing. (Under review)

### Conference Paper

1. Woan-Shiuan Chien, Upadhyay Shreya G., and Chi-Chun Lee. “Balancing Speaker-Rater Fairness for
Gender-Neutral Speech Emotion Recognition.” IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), 2024.
2. Upadhyay Shreya G., Woan-Shiuan Chien, Bo-Hao Su, Carlos Busso, and Chi-Chun Lee. “Towards a
Consortium of Naturalistic Affective Speech Corpora through an Intelligently-Controlled Framework.” Proc.
11th International conference on affective computing and intelligent interactions (ACII), 2023.
3. Luz Martinez-Lucas, Ali Salman, Seong-Gyun Leem, Upadhyay Shreya G., Chi-Chun Lee, and Carlos Busso.
“Analyzing the Effect of Affective Priming on Emotional Annotations.” Proc. 11th International conference
on affective computing and intelligent interactions (ACII), 2023.
4. Upadhyay Shreya G., Luz Martinez-Lucas, Bo-Hao Su, Wei-Cheng Lin, Woan-Shiuan Chien, Ya-Tse Wu,
William Katz, Carlos Busso, and Chi-Chun Lee. “Phonetic Anchor-Based Transfer Learning to Facilitate Unsupervised Cross-Lingual Speech Emotion Recognition.” IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP), 2023.
5. Woan-Shiuan Chien, Upadhyay Shreya G., Wei-Cheng Lin, Ya-Tse Wu, Bo-Hao Su, Carlos Busso, and ChiChun Lee. “Monologue versus Conversation: Differences in Emotion Perception and Acoustic Expressivity.”
Proc. 10th International conference on affective computing and intelligent interactions (ACII), 2022.
6. Upadhyay Shreya G., Bo-Hao Su, and Chi-Chun Lee. “Improving Induced Valence Recognition by Integrating Acoustic Sound Semantics in Movies.” 30th European Signal Processing Conference (EUSIPCO),
2022.
7. Upadhyay Shreya G., Bo-Hao Su, and Chi-Chun Lee. “Attentive Convolutional Recurrent Neural Network
Using Phoneme-Level Acoustic Representation for Rare Sound Event Detection.” Proc. Interspeech, 2020.
8. Upadhyay, Shreya G., and Kavita M. Kelkar. “Predicting Learner’s Confidence from their Behaviour Using
a Judgement Questionnaire.” Fourth International Conference on Computing Communication Control and
Automation (ICCUBEA). IEEE, 2018.

### Accepted Abstract

1. Upadhyay Shreya G., Bo-Hao Su, and Chi-Chun Lee. “Improving Induced Valence Recognition by Integrating Acoustic Sound Semantics in Movies.” Women in Machine Learning (WiML) workshop, NeurIPS,
2022.
2. Upadhyay, Shreya G., and Kavita M. Kelkar. “Accent Classification using Audio-based Features.” 2018
Young Female Researchers in Speech Science and Technology workshop, Interspeech, 2018
